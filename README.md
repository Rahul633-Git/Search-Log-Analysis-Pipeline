# ğŸ“Š Search Log Analysis & Expansion Intelligence Pipeline

[![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=for-the-badge&logo=databricks&logoColor=white)](https://databricks.com/)
[![Apache Spark](https://img.shields.io/badge/Apache_Spark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)](https://spark.apache.org/)
[![Delta Lake](https://img.shields.io/badge/Delta_Lake-00ADD8?style=for-the-badge&logo=databricks&logoColor=white)](https://delta.io/)
[![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)

> **Production-grade ETL pipeline implementing Medallion Architecture to identify high-demand expansion regions from ride-search error logs**

---

## ğŸš€ Overview

This project demonstrates an **end-to-end data engineering solution** built on **Databricks** using **PySpark** and **Delta Lake**. It implements the industry-standard **Medallion Architecture** (Bronze â†’ Silver â†’ Gold) to process ride-search logs and generate actionable expansion intelligence metrics.

The pipeline identifies under-served markets with high demand, enabling data-driven expansion decisions for ride-hailing platforms.

### Key Highlights
- âœ… **Production-oriented design** with data quality enforcement
- âœ… **Automated orchestration** via Databricks Workflows
- âœ… **Version-controlled** with Git integration
- âœ… **Scheduled daily execution** for batch processing
- âœ… **Audit-enabled** Bronze layer for traceability
- âœ… **Business-focused** Gold layer metrics

---

## ğŸ—ï¸ Architecture

The pipeline follows the **Medallion Architecture** pattern with **flexible data source connectivity**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Data Source Options                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Mock Data â”‚orâ”‚ MySQL â”‚orâ”‚ PostgreSQL â”‚  â”‚
â”‚  â”‚ Generator â”‚  â”‚   DB  â”‚  â”‚     DB     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚             â”‚          â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     Bronze Layer        â”‚ â—„â”€â”€ Raw Data Landing (Audit-Enabled)
         â”‚     (Delta Table)       â”‚     â€¢ Schema enforcement
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â€¢ Ingestion metadata
                     â”‚                   â€¢ Partitioned storage
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     Silver Layer        â”‚ â—„â”€â”€ Data Quality & Transformation
         â”‚     (Delta Table)       â”‚     â€¢ Type casting
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â€¢ Data validation
                     â”‚                   â€¢ Outlier removal
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      Gold Layer         â”‚ â—„â”€â”€ Business Intelligence
         â”‚     (Delta Table)       â”‚     â€¢ Aggregated metrics
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â€¢ Expansion signals
                     â”‚                   â€¢ City ranking
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Analytics/Dashboard   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”Œ Data Source Flexibility

This pipeline supports **multiple ingestion patterns**:

| Source | Use Case | Implementation |
|--------|----------|----------------|
| **Mock Data Generator** | Development, Testing, Demos | Python synthetic data generation |
| **MySQL Database** | Production OLTP source | JDBC connector with incremental load |
| **PostgreSQL Database** | Production OLTP source | JDBC connector with incremental load |
| **Cloud Storage** | File-based ingestion | S3, ADLS, GCS support |

---

## ğŸ“ Project Structure

```
Search-Log-Analysis-Pipeline/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 00_data_ingestion/
â”‚   â”‚   â””â”€â”€ mock_data_generator.ipynb  or mysql/postgres_connector   # incase of direct db connection 
â”‚   â”‚                                                                # here only workring with ~100k mock data 
â”‚   â”‚   
â”‚   â”‚
â”‚   â”œâ”€â”€ 01_bronze_layer.ipynb             # Raw data landing
â”‚   â”œâ”€â”€ 02_silver_layer.ipynb             # Data cleaning & validation
â”‚   â””â”€â”€ 03_gold_layer.ipynb               # Business metrics computation
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ pipeline_config.py                # Centralized configuration
â”‚   â”œâ”€â”€ db_connections.py                 # Database connection configs
â”‚   â””â”€â”€ schemas.py                        # Schema definitions
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ setup_source_db.sql               # Source database setup (MySQL/PostgreSQL)
â”‚
â””â”€â”€ README.md                              # Project documentation

---





## âš™ï¸ Orchestration & Automation

### Databricks Workflow

The pipeline is orchestrated using **Databricks Workflows** with the following DAG:

```
generate_mock_data
        â†“
bronze_layer
        â†“
silver_layer
        â†“
gold_layer
```

### Job Configuration
- **Schedule**: Daily automated execution
- **Retry policy**: 3 attempts on failure
- **Compute**: Serverless / Job cluster
- **Source**: Git-integrated (runs from `main` branch)
- **Version control**: Each execution tied to specific commit SHA

---

## ğŸ”„ Version Control & CI/CD Readiness

### Git Integration
- âœ… All notebooks version-controlled in GitHub
- âœ… Job execution linked to specific commits
- âœ… Reproducible pipeline runs
- âœ… Branch-based development workflow

### Production Safety
- Commit-based execution ensures consistency
- Rollback capability via Git history
- Immutable execution artifacts

---

## ğŸ§  Key Engineering Concepts Demonstrated

- âœ… **Medallion Architecture** â€“ Industry-standard data lakehouse pattern
- âœ… **Delta Lake** â€“ ACID transactions, time travel, schema evolution
- âœ… **Multi-Source Ingestion** â€“ Mock data, MySQL, PostgreSQL connectivity
- âœ… **JDBC Connectivity** â€“ Production database integration
- âœ… **Incremental Loading** â€“ Watermark-based delta loads
- âœ… **Schema Enforcement** â€“ Strong typing and validation
- âœ… **Data Quality Validation** â€“ Automated quality gates
- âœ… **Window Functions** â€“ Advanced SQL analytics
- âœ… **Business Metric Engineering** â€“ Translating raw data to insights
- âœ… **Workflow Orchestration** â€“ Automated DAG execution
- âœ… **Batch Processing** â€“ Scheduled ETL jobs
- âœ… **Security Best Practices** â€“ Secrets management
- âœ… **Version Control** â€“ Git-based development
- âœ… **Modular Design** â€“ Reusable configuration

---

## ğŸ“ˆ Business Use Case

### Problem Statement
A ride-hailing company needs to identify which cities to expand into next.

### Solution
This pipeline analyzes search error logs to:
1. **Identify** cities with high search demand
2. **Detect** supply-demand gaps (no service area, no drivers nearby)
3. **Rank** cities by expansion priority
4. **Support** data-driven expansion decisions

### Impact
- ğŸ“Š Quantified expansion opportunities
- ğŸ¯ Prioritized market entry strategy
- ğŸ’° Optimized resource allocation

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| **Platform** | Databricks |
| **Storage** | Delta Lake |
| **Processing** | Apache Spark (PySpark) |
| **Orchestration** | Databricks Workflows |
| **Version Control** | Git / GitHub |
| **Language** | Python |
| **Data Sources** | Mock Data / MySQL / PostgreSQL |
| **Connectivity** | JDBC (MySQL Connector, PostgreSQL Driver) |
| **Security** | Databricks Secrets |

---

## ğŸ“Š Sample Output

### Gold Layer â€“ Top Expansion Candidates

| rank | city | total_searches | expansion_signal_count | signal_ratio_pct |
|------|------|----------------|------------------------|------------------|
| 1 | Boston | 1250 | 687 | 54.96 |
| 2 | Austin | 1180 | 623 | 52.80 |
| 3 | Portland | 1095 | 568 | 51.87 |
| 4 | Denver | 1032 | 531 | 51.45 |
| 5 | Seattle | 978 | 487 | 49.79 |



