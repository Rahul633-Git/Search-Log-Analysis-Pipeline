{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54daab86-9015-4931-9db4-8afc770f5fd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PHASE 1 — Mock Data Generator (~100K rows)\n",
    "# Search Log Analysis Pipeline | Ride-Hailing App (India)\n",
    "#\n",
    "# HOW TO USE:\n",
    "#   1. Open your Databricks workspace\n",
    "#   2. Create a new Notebook → name it \"01_generate_mock_data\" → Language: Python\n",
    "#   3. Copy-paste this entire script into Cell 1\n",
    "#   4. Click \"Run All\"\n",
    "#   5. CSV saved to: /FileStore/search_logs/raw_search_logs.csv\n",
    "#\n",
    "# EXPECTED OUTPUT: ~100,000 rows\n",
    "#   - Active cities    (10 cities x 4,000-5,000 rows) = ~45,000 rows\n",
    "#   - Expansion cities (15 cities x 2,500-3,500 rows) = ~45,000 rows\n",
    "#   - 3% dirty records intentionally injected for Silver layer cleaning\n",
    "# =============================================================================\n",
    "\n",
    "import random\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. CITY MASTER DATA\n",
    "#    Active    = Ola already operates here -> mostly successful rides\n",
    "#    Expansion = Ola NOT here yet          -> mostly errors (our expansion signal!)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "ACTIVE_CITIES = [\n",
    "    {\"city\": \"Mumbai\",    \"state\": \"Maharashtra\",   \"lat\": 19.0760, \"lng\": 72.8777, \"tier\": 1},\n",
    "    {\"city\": \"Delhi\",     \"state\": \"Delhi\",         \"lat\": 28.7041, \"lng\": 77.1025, \"tier\": 1},\n",
    "    {\"city\": \"Bangalore\", \"state\": \"Karnataka\",     \"lat\": 12.9716, \"lng\": 77.5946, \"tier\": 1},\n",
    "    {\"city\": \"Hyderabad\", \"state\": \"Telangana\",     \"lat\": 17.3850, \"lng\": 78.4867, \"tier\": 1},\n",
    "    {\"city\": \"Chennai\",   \"state\": \"Tamil Nadu\",    \"lat\": 13.0827, \"lng\": 80.2707, \"tier\": 1},\n",
    "    {\"city\": \"Kolkata\",   \"state\": \"West Bengal\",   \"lat\": 22.5726, \"lng\": 88.3639, \"tier\": 1},\n",
    "    {\"city\": \"Pune\",      \"state\": \"Maharashtra\",   \"lat\": 18.5204, \"lng\": 73.8567, \"tier\": 2},\n",
    "    {\"city\": \"Ahmedabad\", \"state\": \"Gujarat\",       \"lat\": 23.0225, \"lng\": 72.5714, \"tier\": 2},\n",
    "    {\"city\": \"Jaipur\",    \"state\": \"Rajasthan\",     \"lat\": 26.9124, \"lng\": 75.7873, \"tier\": 2},\n",
    "    {\"city\": \"Lucknow\",   \"state\": \"Uttar Pradesh\", \"lat\": 26.8467, \"lng\": 80.9462, \"tier\": 2},\n",
    "]\n",
    "\n",
    "EXPANSION_CITIES = [\n",
    "    {\"city\": \"Indore\",      \"state\": \"Madhya Pradesh\", \"lat\": 22.7196, \"lng\": 75.8577, \"tier\": 2},\n",
    "    {\"city\": \"Nagpur\",      \"state\": \"Maharashtra\",    \"lat\": 21.1458, \"lng\": 79.0882, \"tier\": 2},\n",
    "    {\"city\": \"Coimbatore\",  \"state\": \"Tamil Nadu\",     \"lat\": 11.0168, \"lng\": 76.9558, \"tier\": 2},\n",
    "    {\"city\": \"Bhopal\",      \"state\": \"Madhya Pradesh\", \"lat\": 23.2599, \"lng\": 77.4126, \"tier\": 2},\n",
    "    {\"city\": \"Surat\",       \"state\": \"Gujarat\",        \"lat\": 21.1702, \"lng\": 72.8311, \"tier\": 2},\n",
    "    {\"city\": \"Vadodara\",    \"state\": \"Gujarat\",        \"lat\": 22.3072, \"lng\": 73.1812, \"tier\": 2},\n",
    "    {\"city\": \"Mysore\",      \"state\": \"Karnataka\",      \"lat\": 12.2958, \"lng\": 76.6394, \"tier\": 2},\n",
    "    {\"city\": \"Vijayawada\",  \"state\": \"Andhra Pradesh\", \"lat\": 16.5062, \"lng\": 80.6480, \"tier\": 2},\n",
    "    {\"city\": \"Patna\",       \"state\": \"Bihar\",          \"lat\": 25.5941, \"lng\": 85.1376, \"tier\": 2},\n",
    "    {\"city\": \"Ranchi\",      \"state\": \"Jharkhand\",      \"lat\": 23.3441, \"lng\": 85.3096, \"tier\": 3},\n",
    "    {\"city\": \"Jodhpur\",     \"state\": \"Rajasthan\",      \"lat\": 26.2389, \"lng\": 73.0243, \"tier\": 3},\n",
    "    {\"city\": \"Guwahati\",    \"state\": \"Assam\",          \"lat\": 26.1445, \"lng\": 91.7362, \"tier\": 3},\n",
    "    {\"city\": \"Bhubaneswar\", \"state\": \"Odisha\",         \"lat\": 20.2961, \"lng\": 85.8245, \"tier\": 3},\n",
    "    {\"city\": \"Dehradun\",    \"state\": \"Uttarakhand\",    \"lat\": 30.3165, \"lng\": 78.0322, \"tier\": 3},\n",
    "    {\"city\": \"Amritsar\",    \"state\": \"Punjab\",         \"lat\": 31.6340, \"lng\": 74.8723, \"tier\": 3},\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. LOOKUP LISTS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "RIDE_TYPES       = [\"Mini\", \"Sedan\", \"Auto\", \"Bike\", \"Prime SUV\", \"Share\"]\n",
    "SUCCESS_STATUSES = [\"COMPLETED\", \"DRIVER_ASSIGNED\", \"EN_ROUTE\"]\n",
    "DEVICES          = [\"Android\", \"iOS\"]\n",
    "APP_VERSIONS     = [\"4.1.2\", \"4.2.0\", \"4.2.1\", \"4.3.0\", \"4.3.5\"]\n",
    "\n",
    "# Error type weights (must sum to 1.0)\n",
    "ERROR_TYPES = {\n",
    "    \"NO_SERVICE_AREA\":   0.45,   # City not covered -> strongest expansion signal\n",
    "    \"NO_DRIVERS_NEARBY\": 0.25,   # Covered but no drivers -> secondary signal\n",
    "    \"SURGE_ABANDONED\":   0.15,   # User quit due to high surge pricing\n",
    "    \"APP_ERROR\":         0.10,   # Technical glitch -> not expansion signal\n",
    "    \"PAYMENT_FAILED\":    0.05,   # Payment issue -> not expansion signal\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. HELPER FUNCTIONS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def random_timestamp(start_days_ago=90):\n",
    "    \"\"\"Random timestamp within the last 90 days.\"\"\"\n",
    "    end       = datetime.now()\n",
    "    start     = end - timedelta(days=start_days_ago)\n",
    "    delta_sec = int((end - start).total_seconds())\n",
    "    return (start + timedelta(seconds=random.randint(0, delta_sec))).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def generate_record(city_info, is_error, inject_dirt=False):\n",
    "    \"\"\"\n",
    "    Generate one search log record.\n",
    "    inject_dirt=True randomly corrupts one field to simulate real messy data.\n",
    "    The Silver layer will detect and handle these dirty records.\n",
    "    \"\"\"\n",
    "    if is_error:\n",
    "        error_type           = random.choices(list(ERROR_TYPES.keys()), weights=list(ERROR_TYPES.values()))[0]\n",
    "        status               = \"FAILED\"\n",
    "        session_duration_sec = random.randint(5, 120)\n",
    "    else:\n",
    "        error_type           = None\n",
    "        status               = random.choice(SUCCESS_STATUSES)\n",
    "        session_duration_sec = random.randint(30, 600)\n",
    "\n",
    "    record = {\n",
    "        \"search_id\":            str(uuid.uuid4()),\n",
    "        \"user_id\":              f\"USR_{random.randint(10000, 99999)}\",\n",
    "        \"timestamp\":            random_timestamp(),\n",
    "        \"city\":                 city_info[\"city\"],\n",
    "        \"state\":                city_info[\"state\"],\n",
    "        \"city_tier\":            city_info[\"tier\"],\n",
    "        \"pickup_lat\":           round(city_info[\"lat\"] + random.uniform(-0.05, 0.05), 6),\n",
    "        \"pickup_lng\":           round(city_info[\"lng\"] + random.uniform(-0.05, 0.05), 6),\n",
    "        \"ride_type\":            random.choice(RIDE_TYPES),\n",
    "        \"status\":               status,\n",
    "        \"error_type\":           error_type,\n",
    "        \"device\":               random.choice(DEVICES),\n",
    "        \"app_version\":          random.choice(APP_VERSIONS),\n",
    "        \"session_duration_sec\": session_duration_sec,\n",
    "        \"is_repeat_search\":     random.choice([True, False]),\n",
    "    }\n",
    "\n",
    "    # Inject ~3% dirty records (nulls / bad values) — Silver layer will clean these\n",
    "    if inject_dirt:\n",
    "        dirty_field = random.choice([\"city\", \"state\", \"pickup_lat\", \"pickup_lng\", \"timestamp\", \"user_id\"])\n",
    "        if dirty_field in (\"pickup_lat\", \"pickup_lng\"):\n",
    "            record[dirty_field] = None           # null coordinate\n",
    "        elif dirty_field == \"timestamp\":\n",
    "            record[dirty_field] = \"INVALID_TS\"   # unparseable timestamp\n",
    "        else:\n",
    "            record[dirty_field] = None           # null string field\n",
    "\n",
    "    return record\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. GENERATE ALL RECORDS\n",
    "#    Active cities    -> 4,000-5,000 records each, 15% error rate  ~ 45,000 rows\n",
    "#    Expansion cities -> 2,500-3,500 records each, 90% error rate  ~ 45,000 rows\n",
    "#    Grand total      -> ~100,000 rows\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "records   = []\n",
    "DIRT_RATE = 0.03   # 3% of all records will have one dirty field\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Generating records for ACTIVE cities (15% error rate)...\")\n",
    "print(\"=\" * 60)\n",
    "for city in ACTIVE_CITIES:\n",
    "    n = random.randint(4000, 5000)\n",
    "    for _ in range(n):\n",
    "        records.append(generate_record(city, is_error=random.random() < 0.15, inject_dirt=random.random() < DIRT_RATE))\n",
    "    print(f\"  {city['city']:<15} Tier-{city['tier']}  {n:,} records\")\n",
    "\n",
    "print()\n",
    "print(\"Generating records for EXPANSION cities (90% error rate)...\")\n",
    "print(\"=\" * 60)\n",
    "for city in EXPANSION_CITIES:\n",
    "    n = random.randint(2500, 3500)\n",
    "    for _ in range(n):\n",
    "        records.append(generate_record(city, is_error=random.random() < 0.90, inject_dirt=random.random() < DIRT_RATE))\n",
    "    print(f\"  {city['city']:<15} Tier-{city['tier']}  {n:,} records\")\n",
    "\n",
    "print()\n",
    "print(f\"TOTAL RECORDS GENERATED: {len(records):,}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. SCHEMA + SPARK DATAFRAME\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"search_id\",            StringType(),  False),\n",
    "    StructField(\"user_id\",              StringType(),  True),\n",
    "    StructField(\"timestamp\",            StringType(),  True),\n",
    "    StructField(\"city\",                 StringType(),  True),\n",
    "    StructField(\"state\",                StringType(),  True),\n",
    "    StructField(\"city_tier\",            IntegerType(), False),\n",
    "    StructField(\"pickup_lat\",           DoubleType(),  True),\n",
    "    StructField(\"pickup_lng\",           DoubleType(),  True),\n",
    "    StructField(\"ride_type\",            StringType(),  False),\n",
    "    StructField(\"status\",               StringType(),  False),\n",
    "    StructField(\"error_type\",           StringType(),  True),\n",
    "    StructField(\"device\",               StringType(),  False),\n",
    "    StructField(\"app_version\",          StringType(),  False),\n",
    "    StructField(\"session_duration_sec\", IntegerType(), False),\n",
    "    StructField(\"is_repeat_search\",     BooleanType(), False),\n",
    "])\n",
    "\n",
    "pdf = pd.DataFrame(records)\n",
    "sdf = spark.createDataFrame(pdf, schema=schema)\n",
    "\n",
    "# Sort by timestamp so it looks like a natural event stream\n",
    "sdf = sdf.orderBy(col(\"timestamp\"))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. SAVE TO FILESTORE (this is the Bronze raw landing zone)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "output_path = \"/FileStore/search_logs/raw_search_logs.csv\"\n",
    "\n",
    "sdf.coalesce(1) \\\n",
    "   .write \\\n",
    "   .mode(\"overwrite\") \\\n",
    "   .option(\"header\", \"true\") \\\n",
    "   .csv(output_path)\n",
    "\n",
    "print(f\"\\nData saved to: {output_path}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7. QUICK VALIDATION — run these to confirm data looks right\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--- RECORD COUNT BY CITY ---\")\n",
    "sdf.groupBy(\"city\", \"state\", \"city_tier\") \\\n",
    "   .count() \\\n",
    "   .orderBy(\"city_tier\", col(\"count\").desc()) \\\n",
    "   .show(30, truncate=False)\n",
    "\n",
    "print(\"--- STATUS BREAKDOWN ---\")\n",
    "sdf.groupBy(\"status\").count().orderBy(col(\"count\").desc()).show()\n",
    "\n",
    "print(\"--- ERROR TYPE BREAKDOWN (FAILED searches only) ---\")\n",
    "sdf.filter(col(\"status\") == \"FAILED\") \\\n",
    "   .groupBy(\"error_type\") \\\n",
    "   .count() \\\n",
    "   .orderBy(col(\"count\").desc()) \\\n",
    "   .show()\n",
    "\n",
    "print(\"--- DIRTY RECORDS INJECTED (null counts per field) ---\")\n",
    "sdf.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c)\n",
    "    for c in [\"city\", \"state\", \"pickup_lat\", \"pickup_lng\", \"timestamp\", \"user_id\"]\n",
    "]).show()\n",
    "\n",
    "print(\"\\nPhase 1 Complete! Next: run 02_bronze_layer.py\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_generate_mock_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
