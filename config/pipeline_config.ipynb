{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da0c0941-5d3d-4d0a-b8ec-117e1b96fabf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# pipeline_config.py\n",
    "# Search Log Analysis Pipeline | Central Configuration\n",
    "#\n",
    "# ALL paths, settings, and constants live here.\n",
    "# Every other notebook imports from this file.\n",
    "# To switch storage (e.g. to ADLS Gen 2), change BASE_PATH only.\n",
    "#\n",
    "# NOTE: Using Unity Catalog Volumes instead of DBFS (FileStore)\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. UNITY CATALOG SETTINGS\n",
    "#    Catalog → Schema → Volume (3 level namespace in Databricks)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "CATALOG_NAME = \"olaride\"        # top level - like a database server\n",
    "SCHEMA_NAME  = \"pipeline\"       # mid level - like a database\n",
    "VOLUME_NAME  = \"raw_data\"       # bottom level - like a folder\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. STORAGE PATHS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# --- Raw CSV Landing Zone (Unity Catalog Volume) ---\n",
    "VOLUME_BASE_PATH = f\"/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/{VOLUME_NAME}\"\n",
    "# RAW_CSV_PATH     = f\"{VOLUME_BASE_PATH}/search_logs/raw_search_logs.csv\"\n",
    "RAW_CSV_PATH     = f\"/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/{VOLUME_NAME}/search_logs/\"\n",
    "\n",
    "# --- Sample paths (for GitHub showcase) ---\n",
    "SAMPLE_INPUT_PATH  = f\"{VOLUME_BASE_PATH}/samples/sample_search_logs.csv\"\n",
    "SAMPLE_OUTPUT_PATH = f\"{VOLUME_BASE_PATH}/samples/expansion_report.csv\"\n",
    "\n",
    "# --- Delta Table Paths ---\n",
    "# Delta tables are registered directly in Unity Catalog (no file path needed)\n",
    "# Format: catalog.schema.table_name\n",
    "BRONZE_TABLE_PATH = f\"{CATALOG_NAME}.{SCHEMA_NAME}.bronze_search_logs\"\n",
    "SILVER_TABLE_PATH = f\"{CATALOG_NAME}.{SCHEMA_NAME}.silver_search_logs\"\n",
    "GOLD_TABLE_PATH   = f\"{CATALOG_NAME}.{SCHEMA_NAME}.gold_expansion_intelligence\"\n",
    "\n",
    "# Short table names (used in CREATE TABLE statements)\n",
    "BRONZE_TABLE = \"bronze_search_logs\"\n",
    "SILVER_TABLE = \"silver_search_logs\"\n",
    "GOLD_TABLE   = \"gold_expansion_intelligence\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. PIPELINE SETTINGS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Data generation settings (Phase 1)\n",
    "RAW_DATA_DAYS     = 90      # generate logs for last 90 days\n",
    "DIRTY_RECORD_RATE = 0.03    # 3% dirty records injected\n",
    "\n",
    "# Silver layer settings (Phase 3)\n",
    "MIN_SESSION_DURATION = 0     # drop records with 0 or negative session duration\n",
    "MAX_SESSION_DURATION = 3600  # drop records with session > 1 hour (outliers)\n",
    "\n",
    "# Gold layer settings (Phase 4)\n",
    "MIN_SEARCHES_FOR_SIGNAL = 100  # city needs at least 100 searches to qualify\n",
    "TOP_N_CITIES            = 10   # show top 10 expansion candidate cities\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. EXPANSION SIGNAL DEFINITION\n",
    "#    Only these error types count as real expansion demand signals\n",
    "#    APP_ERROR and PAYMENT_FAILED are technical issues, not demand signals\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "EXPANSION_ERROR_TYPES = [\n",
    "    \"NO_SERVICE_AREA\",    # strongest signal - city not covered at all\n",
    "    \"NO_DRIVERS_NEARBY\",  # secondary signal - covered but no supply\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. APP SETTINGS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "APP_NAME   = \"OlaRide-Search-Log-Pipeline\"\n",
    "LOG_LEVEL  = \"INFO\"\n",
    "WRITE_MODE = \"overwrite\"   # overwrite for dev, append for production\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. PRINT CONFIG SUMMARY (runs when this file is imported)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"  {APP_NAME}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  CATALOG          : {CATALOG_NAME}\")\n",
    "print(f\"  SCHEMA           : {SCHEMA_NAME}\")\n",
    "print(f\"  VOLUME           : {VOLUME_NAME}\")\n",
    "print(f\"  RAW_CSV_PATH     : {RAW_CSV_PATH}\")\n",
    "print(f\"  BRONZE_TABLE     : {BRONZE_TABLE_PATH}\")\n",
    "print(f\"  SILVER_TABLE     : {SILVER_TABLE_PATH}\")\n",
    "print(f\"  GOLD_TABLE       : {GOLD_TABLE_PATH}\")\n",
    "print(f\"  WRITE_MODE       : {WRITE_MODE}\")\n",
    "print(\"=\" * 60)\n",
    "print(\"  Config loaded successfully!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1bd2f7f-7ecb-4b9f-9026-1256cf881d09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pipeline_config",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
